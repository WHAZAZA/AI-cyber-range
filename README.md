# ğŸ”¥ AI Cyber Range â€” The Complete OWASP Top 10 for LLM Security Lab

### **Build â€¢ Break â€¢ Secure** Large Language Models with a Fully Automated Offensive + Defensive Cyber Range

<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=rect&color=0:001F3F,100:00FFFF&height=120&section=header&text=âš”ï¸%20AI%20CYBER%20RANGE%20â€”%20LLM%20SECURITY%20LAB%20âš”ï¸&fontSize=32&fontColor=FFFFFF&fontAlignY=35&desc=Hands-On%20OWASP%20Top%2010%20for%20LLMs%20Training%20Environment&descAlignY=60&descAlign=50"/>
</p>

<p align="center">
  <b>Created by <a href="https://github.com/Mr-Infect">Mr-Infect</a></b><br>
  <i>A next-generation AI Security Playground for Students, Engineers, & Red Teams</i>
</p>

---

# âš”ï¸ Overview

**AI Cyber Range â€“ OWASP Top 10 for LLMs** is a **cutting-edge AI Penetration Testing Lab** engineered to simulate **real-world LLM vulnerabilities** in a safe, automated, Docker-powered environment.

This platform enables:

* AI Security researchers to **experiment with adversarial AI attacks**
* Red teamers to **practice offensive AI techniques**
* Educators to **demonstrate LLM risks interactively**
* Engineers to **validate AI product security**

Every module replicates attack paths and exploitation vectors aligned with the **OWASP Top 10 for Large Language Models** â€” making it one of the most comprehensive **AI Security Training Environments** available today.

---

# ğŸŒ High-Impact SEO Keywords

*(Expertly curated for Google Discover, GitHub Search, AI Security queries)*

> **AI Cyber Range**, **OWASP Top 10 for LLMs**, **AI Penetration Testing Lab**,
> **LLM Red Team Training**, **Prompt Injection Testing Lab**,
> **AI Security Playground**, **AI Threat Simulation**, **LLM Vulnerability Research**,
> **AI Security Engineer Toolkit**, **Adversarial Machine Learning Lab**,
> **AI Offensive Security**, **AI Security Hands-On Training**,
> **Ethical Hacking with LLMs**, **Secure AI Application Development**,
> **AI Attack Surface Modeling**, **LLM API Exploitation**,
> **LLM Model Theft Simulation**, **Training Data Poisoning Scenarios**

---

# ğŸ§© Key Features

* ğŸš€ **One-click setup** with automated dependency installations
* ğŸ§± **Full Docker isolation** for every vulnerability
* ğŸ¯ Covers all **OWASP LLM Top 10** categories
* ğŸ§  Progression from **Beginner â†’ Advanced Attack Scenarios**
* ğŸ¨ Premium **ASCII-driven CLI UX** (Rich Text + Inquirer)
* ğŸ” **Randomized SHA-256 flags** per session
* ğŸ” **Auto-resetting labs** on challenge completion
* ğŸŒ 100% **offline**, secure, self-contained
* ğŸ§ª **Safe adversarial model behavior simulations**
* ğŸ“¡ **Local browser interface** for each vulnerable LLM endpoint

Designed for **learning, teaching, experimenting, and real-world validation**.

---

# ğŸ§± Project Architecture

```bash
AI-cyber-range/
â”‚
â”œâ”€â”€ config/                    # Lab configurations (YAML)
â”‚   â””â”€â”€ labs.yaml
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup.sh               # Automated installer
â”‚   â””â”€â”€ labctl.py              # Main CLI + lab manager
â”‚
â”œâ”€â”€ common/
â”‚   â””â”€â”€ base.Dockerfile        # Shared base image
â”‚
â”œâ”€â”€ dockerfiles/               # Per-vulnerability Dockerfiles
â”‚   â””â”€â”€ LLM01â€“LLM10/
â”‚
â”œâ”€â”€ labs/                      # Individual lab implementations
â”‚   â”œâ”€â”€ LLM01/â€¦                # Prompt Injection
â”‚   â”œâ”€â”€ LLM02/â€¦                # Output Handling
â”‚   â”œâ”€â”€ â€¦  
â”‚   â””â”€â”€ LLM10/â€¦                # Model Theft
â”‚
â””â”€â”€ README.md                  # You're reading it
```

---

# âš™ï¸ Prerequisites

* **Ubuntu / Debian / WSL 2** (recommended)
* **Python 3.10+**
* **Docker Engine + Docker Compose**
* **Git**

Everything else is automated.

---

# ğŸš€ Installation (Fully Automated)

```bash
git clone https://github.com/Mr-Infect/AI-cyber-range.git
cd AI-cyber-range
chmod +x scripts/setup.sh
./scripts/setup.sh
```

### What the Installer Solves for You

* Installs Python, pip, virtualenv
* Installs Docker + Compose
* Fixes Docker permissions
* Validates container runtime
* Builds the common base image
* Prepares labs for orchestration

---

# ğŸ§  Launch the Cyber Range

```bash
python3 scripts/labctl.py
```

Expected UI:

```
  ___    _____   ____   ____ 
 / _ \  |_   _| |  _ \ / ___|
| | | |   | |   | |_) | |    
| |_| |   | |   |  __/| |___ 
 \___/    |_|   |_|    \____|

Welcome to the LLM OWASP Practice Range.
```

### Workflow

1. Pick a vulnerability (LLM01â€“LLM10)
2. Choose a scenario
3. Select difficulty
4. A Dockerized LLM instance spins up
5. Visit the local URL
6. Exploit the lab â†’ Extract the flag
7. Lab resets â†’ Repeat

Fast. Clean. Secure.

---

# ğŸ§ª Example Session

```bash
? Vulnerability: LLM01 - Prompt Injection
? Scenario: lab01_basic_direct
? Difficulty: easy

â ‹ Deploying environment...
Lab ready at: http://localhost:8001
Paste your captured flag:
```

---

# ğŸ§° Pro-User One-Liner

```bash
git clone https://github.com/Mr-Infect/AI-cyber-range.git && \
cd AI-cyber-range && \
chmod +x scripts/setup.sh && \
./scripts/setup.sh && \
python3 scripts/labctl.py
```

---

# ğŸ“š OWASP Top 10 for LLMs â€” Full Coverage

| ID    | Vulnerability               | Focus Area                            |
| ----- | --------------------------- | ------------------------------------- |
| LLM01 | Prompt Injection            | Input manipulation, bypasses          |
| LLM02 | Insecure Output Handling    | XSS, HTML/JS bleeding                 |
| LLM03 | Training Data Poisoning     | Compromised datasets                  |
| LLM04 | Model Denial of Service     | Token floods, infinite loops          |
| LLM05 | Supply Chain Vulnerability  | Malicious dependencies                |
| LLM06 | Sensitive Data Exposure     | PII, keys, internal secrets           |
| LLM07 | Unauthorized Code Execution | Shell/code execution via prompts      |
| LLM08 | Excessive Agency            | Unsafe tool-use, over-delegation      |
| LLM09 | Overreliance on LLMs        | Bad automation + blind trust          |
| LLM10 | Model Theft                 | Output-based model extraction attacks |

---

# ğŸ§‘â€ğŸ« Ideal Audience

* Cybersecurity Students
* AI/ML Engineers
* Penetration Testers
* Red Team Operators
* SOC Analysts exploring AI threats
* Security Trainers & Professors
* AI Product Teams validating safety

If you work in **AI + Security**, this range is your sandbox.

---

# ğŸª„ Tech Stack

* **Python FastAPI** (vulnerable LLM endpoints)
* **Docker + Docker Compose**
* **YAML Configuration Management**
* **HTML/CSS Micro-Frontends**
* **CLI Engine: Rich + Inquirer**
* **SHA256 Random Flag Generator**

---

# ğŸ§± Architecture Diagram

```
+--------------------------------------------------+
|                    labctl.py                     |
|     Orchestration â€¢ User Interface â€¢ IA Logic    |
+--------------------------------------------------+
                       â”‚
                       â–¼
             +------------------------+
             |   Docker Compose       |
             +------------------------+
                       â”‚
                       â–¼
         +--------------------------------+
         |  Vulnerable LLM Microservice   |
         |     (FastAPI + HTML UI)        |
         +--------------------------------+
                       â”‚
                       â–¼
              Local Browser Interface
```

---

# ğŸ§© Troubleshooting Guide

### Docker not running

```bash
sudo systemctl start docker
sudo usermod -aG docker $USER
newgrp docker
```

### containerd.io error

```bash
sudo apt remove containerd
sudo apt install containerd.io
```

Re-run:

```bash
python3 scripts/labctl.py
```

---

# â˜• Support the Developer

<p align="center">
  <a href="https://www.buymeacoffee.com/MrInfect" target="_blank">
    <img src="https://img.shields.io/badge/â˜•-Support%20Development-blue?style=for-the-badge&logo=buymeacoffee">
  </a>
</p>

Your support fuels new labs, advanced difficulty modes, and future LLM attack modules.

---

# ğŸ“£ Contributions

Pull requests, issue reports, and new vulnerability ideas are **always welcome**.

* Submit bugs
* Suggest improvements
* Build new lab modules
* Extend the AI attack catalog

This project grows through collaboration.

---

# ğŸ§¾ License

This project is released under the **MIT License**.
Use it, customize it, fork it â€” just credit **Mr-Infect**.

---

<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=0:001F3F,100:00FFFF&height=130&section=footer&text=Developed%20by%20Mr-Infect&fontSize=22&fontColor=FFFFFF"/>
</p>


Just say the word.
